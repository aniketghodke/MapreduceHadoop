{\rtf1\ansi\ansicpg1252\cocoartf1347\cocoasubrtf570
{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720

\f0\fs26 \cf0 \expnd0\expndtw0\kerning0
2015-04-21 21:25:18,487 INFO org.apache.hadoop.fs.s3native.NativeS3FileSystem (main): Created AmazonS3 with InstanceProfileCredentialsProvider\
2015-04-21 21:25:23,629 INFO org.apache.hadoop.mapred.JobClient (main): Default number of map tasks: null\
2015-04-21 21:25:23,629 INFO org.apache.hadoop.mapred.JobClient (main): Setting default number of map tasks based on cluster size to : 20\
2015-04-21 21:25:23,629 INFO org.apache.hadoop.mapred.JobClient (main): Default number of reduce tasks: 0\
2015-04-21 21:25:27,635 INFO org.apache.hadoop.security.ShellBasedUnixGroupsMapping (main): add hadoop to shell userGroupsCache\
2015-04-21 21:25:27,639 INFO org.apache.hadoop.mapred.JobClient (main): Setting group to hadoop\
2015-04-21 21:25:28,226 INFO org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore (main): nextMarker: DataViz1/_SUCCESS\
2015-04-21 21:25:28,226 INFO org.apache.hadoop.fs.s3native.NativeS3FileSystem (main): listStatus s3://projectdataaniket/DataViz1\
2015-04-21 21:25:28,419 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat (main): Total input paths to process : 5\
2015-04-21 21:25:28,495 INFO com.hadoop.compression.lzo.GPLNativeCodeLoader (main): Loaded native gpl library\
2015-04-21 21:25:28,508 WARN com.hadoop.compression.lzo.LzoCodec (main): Could not find build properties file with revision hash\
2015-04-21 21:25:28,508 INFO com.hadoop.compression.lzo.LzoCodec (main): Successfully loaded & initialized native-lzo library [hadoop-lzo rev UNKNOWN]\
2015-04-21 21:25:28,524 WARN org.apache.hadoop.io.compress.snappy.LoadSnappy (main): Snappy native library is available\
2015-04-21 21:25:28,524 INFO org.apache.hadoop.io.compress.snappy.LoadSnappy (main): Snappy native library loaded\
2015-04-21 21:25:30,004 INFO org.apache.hadoop.mapred.JobClient (main): Running job: job_201504212122_0001\
2015-04-21 21:25:31,008 INFO org.apache.hadoop.mapred.JobClient (main):  map 0% reduce 0%\
2015-04-21 21:26:39,337 INFO org.apache.hadoop.mapred.JobClient (main):  map 20% reduce 0%\
2015-04-21 21:26:48,362 INFO org.apache.hadoop.mapred.JobClient (main):  map 40% reduce 0%\
2015-04-21 21:26:54,375 INFO org.apache.hadoop.mapred.JobClient (main):  map 60% reduce 0%\
2015-04-21 21:27:00,414 INFO org.apache.hadoop.mapred.JobClient (main):  map 80% reduce 0%\
2015-04-21 21:27:06,448 INFO org.apache.hadoop.mapred.JobClient (main):  map 100% reduce 0%\
2015-04-21 21:27:11,464 INFO org.apache.hadoop.mapred.JobClient (main): Job complete: job_201504212122_0001\
2015-04-21 21:27:11,520 INFO org.apache.hadoop.mapred.JobClient (main): Counters: 20\
2015-04-21 21:27:11,520 INFO org.apache.hadoop.mapred.JobClient (main):   Job Counters \
2015-04-21 21:27:11,520 INFO org.apache.hadoop.mapred.JobClient (main):     Total time spent by all maps waiting after reserving slots (ms)=0\
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):     Total time spent by all reduces waiting after reserving slots (ms)=0\
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):     Rack-local map tasks=9\
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):     SLOTS_MILLIS_MAPS=110773\
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):     SLOTS_MILLIS_REDUCES=0\
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):     Launched map tasks=9\
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):   File Output Format Counters \
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):     Bytes Written=518138\
2015-04-21 21:27:11,521 INFO org.apache.hadoop.mapred.JobClient (main):   FileSystemCounters\
2015-04-21 21:27:11,522 INFO org.apache.hadoop.mapred.JobClient (main):     FILE_BYTES_WRITTEN=121000\
2015-04-21 21:27:11,522 INFO org.apache.hadoop.mapred.JobClient (main):     HDFS_BYTES_READ=545\
2015-04-21 21:27:11,522 INFO org.apache.hadoop.mapred.JobClient (main):     S3_BYTES_READ=1212652\
2015-04-21 21:27:11,522 INFO org.apache.hadoop.mapred.JobClient (main):     S3_BYTES_WRITTEN=518138\
2015-04-21 21:27:11,522 INFO org.apache.hadoop.mapred.JobClient (main):   File Input Format Counters \
2015-04-21 21:27:11,522 INFO org.apache.hadoop.mapred.JobClient (main):     Bytes Read=1212652\
2015-04-21 21:27:11,522 INFO org.apache.hadoop.mapred.JobClient (main):   Map-Reduce Framework\
2015-04-21 21:27:11,523 INFO org.apache.hadoop.mapred.JobClient (main):     Total committed heap usage (bytes)=131727360\
2015-04-21 21:27:11,523 INFO org.apache.hadoop.mapred.JobClient (main):     CPU time spent (ms)=6220\
2015-04-21 21:27:11,523 INFO org.apache.hadoop.mapred.JobClient (main):     Map input records=17770\
2015-04-21 21:27:11,523 INFO org.apache.hadoop.mapred.JobClient (main):     Map output records=17770\
2015-04-21 21:27:11,523 INFO org.apache.hadoop.mapred.JobClient (main):     Physical memory (bytes) snapshot=487919616\
2015-04-21 21:27:11,523 INFO org.apache.hadoop.mapred.JobClient (main):     Spilled Records=0\
2015-04-21 21:27:11,524 INFO org.apache.hadoop.mapred.JobClient (main):     SPLIT_RAW_BYTES=545\
2015-04-21 21:27:11,524 INFO org.apache.hadoop.mapred.JobClient (main):     Virtual memory (bytes) snapshot=3239936000}